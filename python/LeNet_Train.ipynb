{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import h5py\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'channels_first'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.backend.image_data_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255.\n",
    "x_test = x_test / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(-1, 1, 28, 28)\n",
    "x_test = x_test.reshape(-1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend.tensorflow_backend as tfback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_available_gpus():  \n",
    "\n",
    "    if tfback._LOCAL_DEVICES is None:  \n",
    "        devices = tf.config.list_logical_devices()  \n",
    "        tfback._LOCAL_DEVICES = [x.name for x in devices]  \n",
    "    return [x for x in tfback._LOCAL_DEVICES if 'device:gpu' in x.lower()]\n",
    "\n",
    "\n",
    "tfback._get_available_gpus = _get_available_gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet = Sequential()\n",
    "lenet.add(Conv2D(6, kernel_size=3, strides=1, padding='same', input_shape=(1, 28, 28), activation=\"relu\", \\\n",
    "                name='conv1', data_format=\"channels_first\"))\n",
    "\n",
    "lenet.add(MaxPool2D(pool_size=2, strides=2, name='pool1', data_format='channels_first'))\n",
    "\n",
    "lenet.add(Conv2D(16, kernel_size=5, strides=1, padding='valid', activation=\"relu\", \\\n",
    "                 name='conv2', data_format=\"channels_first\"))\n",
    "\n",
    "lenet.add(MaxPool2D(pool_size=2, strides=2, name='pool2', data_format=\"channels_first\"))\n",
    "lenet.add(Flatten(name='flatten', data_format=\"channels_last\"))\n",
    "lenet.add(Dense(120, activation=\"relu\", name='fc1'))\n",
    "lenet.add(Dense(84, activation=\"relu\", name='fc2'))\n",
    "lenet.add(Dense(10, activation='softmax', name='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv2D)               (None, 6, 28, 28)         60        \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 6, 14, 14)         0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 16, 10, 10)        2416      \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 16, 5, 5)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 120)               48120     \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "softmax (Dense)              (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 61,610\n",
      "Trainable params: 61,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lenet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet.compile('sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.8021 - accuracy: 0.7618 - val_loss: 0.2386 - val_accuracy: 0.9274\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.1934 - accuracy: 0.9412 - val_loss: 0.1370 - val_accuracy: 0.9589\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 12s 201us/step - loss: 0.1358 - accuracy: 0.9585 - val_loss: 0.1102 - val_accuracy: 0.9682\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 11s 182us/step - loss: 0.1090 - accuracy: 0.9664 - val_loss: 0.0927 - val_accuracy: 0.9711\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 10s 167us/step - loss: 0.0943 - accuracy: 0.9713 - val_loss: 0.0869 - val_accuracy: 0.9722\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 12s 192us/step - loss: 0.0840 - accuracy: 0.9736 - val_loss: 0.0739 - val_accuracy: 0.9760\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 11s 186us/step - loss: 0.0761 - accuracy: 0.9765 - val_loss: 0.0717 - val_accuracy: 0.9783\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 11s 177us/step - loss: 0.0697 - accuracy: 0.9786 - val_loss: 0.0776 - val_accuracy: 0.9749\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 13s 210us/step - loss: 0.0642 - accuracy: 0.9801 - val_loss: 0.0634 - val_accuracy: 0.9788\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 10s 169us/step - loss: 0.0605 - accuracy: 0.9810 - val_loss: 0.0986 - val_accuracy: 0.9680\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 11s 181us/step - loss: 0.0565 - accuracy: 0.9824 - val_loss: 0.0651 - val_accuracy: 0.9785\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 11s 181us/step - loss: 0.0533 - accuracy: 0.9830 - val_loss: 0.0598 - val_accuracy: 0.9798\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 11s 191us/step - loss: 0.0492 - accuracy: 0.9844 - val_loss: 0.0547 - val_accuracy: 0.9809\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 10s 167us/step - loss: 0.0473 - accuracy: 0.9853 - val_loss: 0.0737 - val_accuracy: 0.9772\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.0445 - accuracy: 0.9861 - val_loss: 0.0521 - val_accuracy: 0.9826\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.0424 - accuracy: 0.9868 - val_loss: 0.0542 - val_accuracy: 0.9829\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 10s 172us/step - loss: 0.0402 - accuracy: 0.9872 - val_loss: 0.0497 - val_accuracy: 0.9830\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 10s 170us/step - loss: 0.0381 - accuracy: 0.9875 - val_loss: 0.0551 - val_accuracy: 0.9819\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.0365 - accuracy: 0.9885 - val_loss: 0.0516 - val_accuracy: 0.9835.98\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.0353 - accuracy: 0.9885 - val_loss: 0.0480 - val_accuracy: 0.9842\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 0.0336 - accuracy: 0.9895 - val_loss: 0.0630 - val_accuracy: 0.9806\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.0324 - accuracy: 0.9895 - val_loss: 0.0520 - val_accuracy: 0.9841\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 13s 210us/step - loss: 0.0306 - accuracy: 0.9905 - val_loss: 0.0533 - val_accuracy: 0.9827\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 14s 227us/step - loss: 0.0295 - accuracy: 0.9908 - val_loss: 0.0569 - val_accuracy: 0.9825\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 13s 225us/step - loss: 0.0283 - accuracy: 0.9910 - val_loss: 0.0503 - val_accuracy: 0.9847\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 11s 178us/step - loss: 0.0273 - accuracy: 0.9912 - val_loss: 0.0693 - val_accuracy: 0.9784\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 10s 172us/step - loss: 0.0263 - accuracy: 0.9916 - val_loss: 0.0488 - val_accuracy: 0.9847\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 10s 171us/step - loss: 0.0242 - accuracy: 0.9925 - val_loss: 0.0452 - val_accuracy: 0.9858\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 14s 230us/step - loss: 0.0233 - accuracy: 0.9928 - val_loss: 0.0460 - val_accuracy: 0.9862\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 11s 188us/step - loss: 0.0228 - accuracy: 0.9926 - val_loss: 0.0513 - val_accuracy: 0.9846\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 0.0224 - accuracy: 0.9930 - val_loss: 0.0487 - val_accuracy: 0.9858\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 10s 167us/step - loss: 0.0210 - accuracy: 0.9938 - val_loss: 0.0510 - val_accuracy: 0.9846\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 11s 185us/step - loss: 0.0203 - accuracy: 0.9935 - val_loss: 0.0445 - val_accuracy: 0.9867\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 13s 221us/step - loss: 0.0194 - accuracy: 0.9940 - val_loss: 0.0435 - val_accuracy: 0.9867\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 11s 183us/step - loss: 0.0185 - accuracy: 0.9945 - val_loss: 0.0491 - val_accuracy: 0.9856\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.0176 - accuracy: 0.9945 - val_loss: 0.0486 - val_accuracy: 0.9860\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 0.0168 - accuracy: 0.9948 - val_loss: 0.0470 - val_accuracy: 0.9862\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.0166 - accuracy: 0.9947 - val_loss: 0.0532 - val_accuracy: 0.9849\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.0158 - accuracy: 0.9949 - val_loss: 0.0483 - val_accuracy: 0.9864\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 10s 173us/step - loss: 0.0148 - accuracy: 0.9956 - val_loss: 0.0485 - val_accuracy: 0.9866\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 11s 177us/step - loss: 0.0143 - accuracy: 0.9956 - val_loss: 0.0454 - val_accuracy: 0.9863\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 10s 167us/step - loss: 0.0143 - accuracy: 0.9959 - val_loss: 0.0453 - val_accuracy: 0.9870\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.0135 - accuracy: 0.9959 - val_loss: 0.0580 - val_accuracy: 0.9831\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.0128 - accuracy: 0.9962 - val_loss: 0.0521 - val_accuracy: 0.9854\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.0126 - accuracy: 0.9963 - val_loss: 0.0509 - val_accuracy: 0.9861\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.0118 - accuracy: 0.9965 - val_loss: 0.0490 - val_accuracy: 0.9861\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.0113 - accuracy: 0.9968 - val_loss: 0.0573 - val_accuracy: 0.9845\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.0110 - accuracy: 0.9968 - val_loss: 0.0694 - val_accuracy: 0.9820\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.0107 - accuracy: 0.9967 - val_loss: 0.0510 - val_accuracy: 0.9865\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.0102 - accuracy: 0.9971 - val_loss: 0.0524 - val_accuracy: 0.9857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x24d38983668>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenet.fit(x_train, y_train, batch_size=64, epochs=50, validation_data=[x_test, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet.save('LeNet_NCHW2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x24d41e80710>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet.load_weights('LeNet_NCHW2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_7 = np.expand_dims(x_test[0], axis=0)\n",
    "pred = lenet.predict(image_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = np.where(pred == np.amax(pred))[1][0]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating...\n",
      "10000/10000 [==============================] - 1s 105us/step\n",
      "[INFO] accuracy: 98.57%\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] evaluating...\")\n",
    "(loss, accuracy) = lenet.evaluate(x_test, y_test, verbose=1)\n",
    "print(\"[INFO] accuracy: {:.2f}%\".format(accuracy * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
